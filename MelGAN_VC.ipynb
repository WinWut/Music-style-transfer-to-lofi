{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WinWut/Music-style-transfer-to-lofi/blob/main/MelGAN_VC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9g5X2Kl94-4"
      },
      "source": [
        "# Python 3.6 Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzPsHBbU3Pu_",
        "outputId": "09954982-2e94-48d3-b917-9a65263ebaae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Waiting for headers] [W\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,046 kB]\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,342 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,690 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,366 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,578 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,228 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,167 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,216 kB]\n",
            "Fetched 17.0 MB in 3s (6,144 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.6-minimal libpython3.6-stdlib python3.6-minimal\n",
            "Suggested packages:\n",
            "  python3.6-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.6-minimal libpython3.6-stdlib python3.6 python3.6-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 4,294 kB of archives.\n",
            "After this operation, 22.1 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.6-minimal amd64 3.6.15-1+focal3 [569 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6-minimal amd64 3.6.15-1+focal3 [1,718 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.6-stdlib amd64 3.6.15-1+focal3 [1,758 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6 amd64 3.6.15-1+focal3 [248 kB]\n",
            "Fetched 4,294 kB in 3s (1,507 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.6-minimal:amd64.\n",
            "(Reading database ... 122520 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.6-minimal_3.6.15-1+focal3_amd64.deb ...\n",
            "Unpacking libpython3.6-minimal:amd64 (3.6.15-1+focal3) ...\n",
            "Selecting previously unselected package python3.6-minimal.\n",
            "Preparing to unpack .../python3.6-minimal_3.6.15-1+focal3_amd64.deb ...\n",
            "Unpacking python3.6-minimal (3.6.15-1+focal3) ...\n",
            "Selecting previously unselected package libpython3.6-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.6-stdlib_3.6.15-1+focal3_amd64.deb ...\n",
            "Unpacking libpython3.6-stdlib:amd64 (3.6.15-1+focal3) ...\n",
            "Selecting previously unselected package python3.6.\n",
            "Preparing to unpack .../python3.6_3.6.15-1+focal3_amd64.deb ...\n",
            "Unpacking python3.6 (3.6.15-1+focal3) ...\n",
            "Setting up libpython3.6-minimal:amd64 (3.6.15-1+focal3) ...\n",
            "Setting up python3.6-minimal (3.6.15-1+focal3) ...\n",
            "Setting up libpython3.6-stdlib:amd64 (3.6.15-1+focal3) ...\n",
            "Setting up python3.6 (3.6.15-1+focal3) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "There are 3 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.10   2         auto mode\n",
            "  1            /usr/bin/python3.10   2         manual mode\n",
            "  2            /usr/bin/python3.6    1         manual mode\n",
            "  3            /usr/bin/python3.8    1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/bin/python3.6 to provide /usr/bin/python3 (python3) in manual mode\n",
            "Python 3.6.15\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.6-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.6-distutils python3.6-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 308 kB of archives.\n",
            "After this operation, 1,232 kB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6-lib2to3 all 3.6.15-1+focal3 [122 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6-distutils all 3.6.15-1+focal3 [187 kB]\n",
            "Fetched 308 kB in 1s (331 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.6-lib2to3.\n",
            "(Reading database ... 123131 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.6-lib2to3_3.6.15-1+focal3_all.deb ...\n",
            "Unpacking python3.6-lib2to3 (3.6.15-1+focal3) ...\n",
            "Selecting previously unselected package python3.6-distutils.\n",
            "Preparing to unpack .../python3.6-distutils_3.6.15-1+focal3_all.deb ...\n",
            "Unpacking python3.6-distutils (3.6.15-1+focal3) ...\n",
            "Setting up python3.6-lib2to3 (3.6.15-1+focal3) ...\n",
            "Setting up python3.6-distutils (3.6.15-1+focal3) ...\n",
            "--2023-05-17 13:00:27--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2578580 (2.5M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.46M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-05-17 13:00:27 (33.3 MB/s) - ‘get-pip.py’ saved [2578580/2578580]\n",
            "\n",
            "ERROR: This script does not work on Python 3.6 The minimum supported Python version is 3.7. Please use https://bootstrap.pypa.io/pip/3.6/get-pip.py instead.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 4 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 2,389 kB of archives.\n",
            "After this operation, 4,933 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.8 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.8 [231 kB]\n",
            "Fetched 2,389 kB in 0s (7,546 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 123270 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Setting up python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 20.0.2\n",
            "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'pip'. No files were found to uninstall.\n",
            "Successfully installed pip-21.3.1\n"
          ]
        }
      ],
      "source": [
        "# first install python 3.7 on notebook\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.6\n",
        "# change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1\n",
        "# select python version\n",
        "!sudo update-alternatives --config python3\n",
        "# check python version\n",
        "!python --version\n",
        "# install pip for new python \n",
        "!sudo apt-get install python3.6-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python get-pip.py\n",
        "# upgrade pip\n",
        "!sudo apt install python3-pip\n",
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDiP1TSD-Pr2"
      },
      "source": [
        "# Installing and importing packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA7NBVmvA_jU"
      },
      "source": [
        "##Installing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V00rptcdKSbq",
        "outputId": "767066ad-2a49-472b-fc82-1a209a2c7fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.1.0\n",
            "  Downloading tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "     |████████████████████████████████| 421.8 MB 19 kB/s              \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.15.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
            "     |████████████████████████████████| 75 kB 4.1 MB/s             \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "     |████████████████████████████████| 50 kB 6.9 MB/s             \n",
            "\u001b[?25hCollecting numpy<2.0,>=1.16.0\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "     |████████████████████████████████| 14.8 MB 50.4 MB/s            \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "     |████████████████████████████████| 448 kB 84.8 MB/s            \n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "     |████████████████████████████████| 65 kB 4.4 MB/s             \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-preprocessing>=1.1.0\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "     |████████████████████████████████| 42 kB 1.5 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Collecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
            "     |████████████████████████████████| 26.1 MB 6.2 MB/s             \n",
            "\u001b[?25hCollecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "     |████████████████████████████████| 4.6 MB 81.0 MB/s            \n",
            "\u001b[?25hCollecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting protobuf>=3.8.0\n",
            "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "     |████████████████████████████████| 1.1 MB 76.4 MB/s            \n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "     |████████████████████████████████| 57 kB 5.1 MB/s             \n",
            "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "     |████████████████████████████████| 3.8 MB 69.1 MB/s            \n",
            "\u001b[?25hCollecting six>=1.12.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting absl-py>=0.7.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "     |████████████████████████████████| 126 kB 75.0 MB/s            \n",
            "\u001b[?25hCollecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "     |████████████████████████████████| 4.0 MB 70.1 MB/s            \n",
            "\u001b[?25hCollecting requests<3,>=2.21.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "     |████████████████████████████████| 63 kB 2.1 MB/s             \n",
            "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "     |████████████████████████████████| 152 kB 68.5 MB/s            \n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "     |████████████████████████████████| 97 kB 7.3 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (45.2.0)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
            "     |████████████████████████████████| 289 kB 72.1 MB/s            \n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "     |████████████████████████████████| 181 kB 86.7 MB/s            \n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "     |████████████████████████████████| 61 kB 116 kB/s             \n",
            "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "     |████████████████████████████████| 156 kB 72.5 MB/s            \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "     |████████████████████████████████| 140 kB 73.4 MB/s            \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Collecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting typing-extensions>=3.6.4\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "     |████████████████████████████████| 83 kB 2.8 MB/s             \n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "     |████████████████████████████████| 151 kB 67.7 MB/s            \n",
            "\u001b[?25hBuilding wheels for collected packages: gast, termcolor\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=2e20b9fedd130c73ff6712adb1a7dc98625c562165bfc1ada6d727052116ceda\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=c574d74c8d2a2271669fa709f318840e75944fb9edfbe1f231f1246777d98fad\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "Successfully built gast termcolor\n",
            "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, zipp, typing-extensions, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, numpy, importlib-metadata, google-auth, dataclasses, cached-property, werkzeug, protobuf, markdown, h5py, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow\n",
            "Successfully installed absl-py-1.4.0 astor-0.8.1 cached-property-1.5.2 cachetools-4.2.4 certifi-2023.5.7 charset-normalizer-2.0.12 dataclasses-0.8 gast-0.2.2 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.48.2 h5py-3.1.0 idna-3.4 importlib-metadata-4.8.3 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.7 numpy-1.19.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.4.1 six-1.16.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 typing-extensions-4.1.1 urllib3-1.26.15 werkzeug-2.0.3 wrapt-1.15.0 zipp-3.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting soundfile\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "     |████████████████████████████████| 1.2 MB 4.1 MB/s            \n",
            "\u001b[?25hCollecting cffi>=1.0\n",
            "  Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\n",
            "     |████████████████████████████████| 402 kB 74.3 MB/s            \n",
            "\u001b[?25hCollecting pycparser\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "     |████████████████████████████████| 118 kB 90.6 MB/s            \n",
            "\u001b[?25hInstalling collected packages: pycparser, cffi, soundfile\n",
            "Successfully installed cffi-1.15.1 pycparser-2.21 soundfile-0.12.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_cffi_backend",
                  "cffi"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchaudio==0.5.0\n",
            "  Downloading torchaudio-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.2 MB)\n",
            "     |████████████████████████████████| 3.2 MB 4.2 MB/s            \n",
            "\u001b[?25hInstalling collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.5)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
            "     |████████████████████████████████| 11.5 MB 4.1 MB/s            \n",
            "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "     |████████████████████████████████| 98 kB 9.2 MB/s             \n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting python-dateutil>=2.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "     |████████████████████████████████| 247 kB 63.1 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.5)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
            "     |████████████████████████████████| 1.1 MB 82.3 MB/s            \n",
            "\u001b[?25hCollecting pillow>=6.2.0\n",
            "  Downloading Pillow-8.4.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "     |████████████████████████████████| 3.1 MB 59.6 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\n",
            "Installing collected packages: python-dateutil, pyparsing, pillow, kiwisolver, cycler, matplotlib\n",
            "Successfully installed cycler-0.11.0 kiwisolver-1.3.1 matplotlib-3.3.4 pillow-8.4.0 pyparsing-3.0.9 python-dateutil-2.8.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cycler",
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (8.4.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
            "     |████████████████████████████████| 12.4 MB 4.0 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.3.4)\n",
            "Collecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
            "     |████████████████████████████████| 4.4 MB 59.7 MB/s            \n",
            "\u001b[?25hCollecting networkx>=2.0\n",
            "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
            "     |████████████████████████████████| 1.6 MB 75.9 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.19.5)\n",
            "Collecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
            "     |████████████████████████████████| 148 kB 95.2 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (8.4.0)\n",
            "Collecting imageio>=2.3.0\n",
            "  Downloading imageio-2.15.0-py3-none-any.whl (3.3 MB)\n",
            "     |████████████████████████████████| 3.3 MB 73.1 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Collecting decorator<5,>=4.3\n",
            "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.16.0)\n",
            "Installing collected packages: decorator, tifffile, PyWavelets, networkx, imageio, scikit-image\n",
            "Successfully installed PyWavelets-1.1.1 decorator-4.4.2 imageio-2.15.0 networkx-2.5.1 scikit-image-0.17.2 tifffile-2020.9.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "decorator"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting librosa\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "     |████████████████████████████████| 214 kB 4.1 MB/s            \n",
            "\u001b[?25hCollecting numba>=0.45.1\n",
            "  Downloading numba-0.53.1-cp36-cp36m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "     |████████████████████████████████| 3.4 MB 48.1 MB/s            \n",
            "\u001b[?25hCollecting audioread>=2.1.9\n",
            "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
            "     |████████████████████████████████| 377 kB 91.9 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "     |████████████████████████████████| 3.1 MB 83.4 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "     |████████████████████████████████| 40 kB 6.6 MB/s             \n",
            "\u001b[?25hCollecting scikit-learn>=0.19.1\n",
            "  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
            "     |████████████████████████████████| 22.2 MB 1.2 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.12.1)\n",
            "Collecting pooch>=1.0\n",
            "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
            "     |████████████████████████████████| 56 kB 5.0 MB/s             \n",
            "\u001b[?25hCollecting joblib>=0.14\n",
            "  Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
            "     |████████████████████████████████| 309 kB 59.3 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.19.5)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp36-cp36m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "     |████████████████████████████████| 25.3 MB 1.2 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba>=0.45.1->librosa) (45.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa) (2.27.1)\n",
            "Collecting appdirs>=1.3.0\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
            "Building wheels for collected packages: audioread\n",
            "  Building wheel for audioread (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23692 sha256=804b7780ba5f1d0866d3de8b395b3bf5a4a3a99267fecb5a4e79410a4d7619b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/be/fc/a93c5810787b4f37cd2a5336f8291235efbf0da00bb04add66\n",
            "Successfully built audioread\n",
            "Installing collected packages: llvmlite, threadpoolctl, packaging, numba, joblib, appdirs, scikit-learn, resampy, pooch, audioread, librosa\n",
            "Successfully installed appdirs-1.4.4 audioread-3.0.0 joblib-1.1.1 librosa-0.9.2 llvmlite-0.36.0 numba-0.53.1 packaging-21.3 pooch-1.6.0 resampy-0.4.2 scikit-learn-0.24.2 threadpoolctl-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.5.0\n",
            "  Downloading torch-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (752.0 MB)\n",
            "     |████████████████████████████████| 752.0 MB 3.2 kB/s              \n",
            "\u001b[?25hCollecting future\n",
            "  Downloading future-0.18.3.tar.gz (840 kB)\n",
            "     |████████████████████████████████| 840 kB 69.8 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0) (1.19.5)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=c1297f5ef89709b135d2ebe6ffebec2b978b6ce768b79fc1d69280bb815028ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/f1/0c/e56d12b3804345ce5ba34279cbfe583ecafdd1401551457330\n",
            "Successfully built future\n",
            "Installing collected packages: future, torch\n",
            "Successfully installed future-0.18.3 torch-1.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "     |████████████████████████████████| 78 kB 3.5 MB/s             \n",
            "\u001b[?25hCollecting importlib-resources\n",
            "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from importlib-resources->tqdm) (3.6.0)\n",
            "Installing collected packages: importlib-resources, tqdm\n",
            "Successfully installed importlib-resources-5.4.0 tqdm-4.64.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python_version>\"3.7\"\n",
            "  Downloading python_version-0.0.2-py2.py3-none-any.whl (3.4 kB)\n",
            "Building wheels for collected packages: tensorflow-gpu\n",
            "  Building wheel for tensorflow-gpu (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for tensorflow-gpu\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for tensorflow-gpu\n",
            "Failed to build tensorflow-gpu\n",
            "Installing collected packages: python-version, tensorflow-gpu\n",
            "    Running setup.py install for tensorflow-gpu ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-869c17sb/tensorflow-gpu_e563920d458b4e0a95a053be9f8669a3/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-869c17sb/tensorflow-gpu_e563920d458b4e0a95a053be9f8669a3/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-zq598t_j/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.6/tensorflow-gpu Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#We'll be using TF 2.1 and torchaudio\n",
        "\n",
        "\n",
        "!pip install tensorflow==2.1.0\n",
        "import tensorflow as tf\n",
        "!pip install soundfile                    #to save wav files\n",
        "!pip install --no-deps torchaudio==0.5.0\n",
        "!pip install scipy\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n",
        "!pip install scikit-image\n",
        "!pip install librosa\n",
        "!pip install torch==1.5.0\n",
        "!pip install tqdm\n",
        "!pip install tensorflow-gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm00r9SnH-4L",
        "outputId": "6ad1701f-43f4-4811-bfd8-a1da33f4a1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-17 13:05:19--  http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_bdl_arctic-0.95-release.tar.bz2\n",
            "Resolving festvox.org (festvox.org)... 199.4.150.153\n",
            "Connecting to festvox.org (festvox.org)|199.4.150.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94333107 (90M) [application/x-bzip2]\n",
            "Saving to: ‘cmu_us_bdl_arctic-0.95-release.tar.bz2’\n",
            "\n",
            "cmu_us_bdl_arctic-0 100%[===================>]  89.96M  32.0MB/s    in 2.8s    \n",
            "\n",
            "2023-05-17 13:05:23 (32.0 MB/s) - ‘cmu_us_bdl_arctic-0.95-release.tar.bz2’ saved [94333107/94333107]\n",
            "\n",
            "--2023-05-17 13:05:32--  http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_clb_arctic-0.95-release.tar.bz2\n",
            "Resolving festvox.org (festvox.org)... 199.4.150.153\n",
            "Connecting to festvox.org (festvox.org)|199.4.150.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130040259 (124M) [application/x-bzip2]\n",
            "Saving to: ‘cmu_us_clb_arctic-0.95-release.tar.bz2’\n",
            "\n",
            "cmu_us_clb_arctic-0 100%[===================>] 124.02M  37.7MB/s    in 3.7s    \n",
            "\n",
            "2023-05-17 13:05:36 (33.6 MB/s) - ‘cmu_us_clb_arctic-0.95-release.tar.bz2’ saved [130040259/130040259]\n",
            "\n",
            "cmu_us_bdl_arctic\t\t\tcmu_us_clb_arctic-0.95-release.tar.bz2\n",
            "cmu_us_bdl_arctic-0.95-release.tar.bz2\tget-pip.py\n",
            "cmu_us_clb_arctic\t\t\tsample_data\n"
          ]
        }
      ],
      "source": [
        "#Dataset download (Uncomment where needed)\n",
        "\n",
        "#Arctic dataset for voice conversion\n",
        "\n",
        "# !wget --header=\"Host: festvox.org\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: http://festvox.org/cmu_arctic/cmu_arctic/packed/\" \"http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_bdl_arctic-0.95-release.zip\" -O \"cmu_us_bdl_arctic-0.95-release.zip\" -c\n",
        "# !unzip -qq cmu_us_bdl_arctic-0.95-release.zip #MALE1\n",
        "# !wget --header=\"Host: festvox.org\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: http://festvox.org/cmu_arctic/cmu_arctic/packed/\" \"http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_clb_arctic-0.95-release.zip\" -O \"cmu_us_clb_arctic-0.95-release.zip\" -c\n",
        "# !unzip -qq cmu_us_clb_arctic-0.95-release.zip #FEMALE1\n",
        "# !wget --header=\"Host: festvox.org\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: http://festvox.org/cmu_arctic/cmu_arctic/packed/\" \"http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_rms_arctic-0.95-release.zip\" -O \"cmu_us_rms_arctic-0.95-release.zip\" -c\n",
        "# !unzip -qq cmu_us_rms_arctic-0.95-release.zip #MALE2\n",
        "# !wget --header=\"Host: festvox.org\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: http://festvox.org/cmu_arctic/cmu_arctic/packed/\" \"http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_slt_arctic-0.95-release.zip\" -O \"cmu_us_slt_arctic-0.95-release.zip\" -c\n",
        "# !unzip -qq cmu_us_slt_arctic-0.95-release.zip #FEMALE2\n",
        "\n",
        "!wget http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_bdl_arctic-0.95-release.tar.bz2 #MALE1\n",
        "!tar -xf cmu_us_bdl_arctic-0.95-release.tar.bz2\n",
        "!wget http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_clb_arctic-0.95-release.tar.bz2 #FEMALE1\n",
        "!tar -xf cmu_us_clb_arctic-0.95-release.tar.bz2\n",
        "# !wget http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_rms_arctic-0.95-release.tar.bz2 #MALE2\n",
        "# !tar -xf cmu_us_rms_arctic-0.95-release.tar.bz2\n",
        "# !wget http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_slt_arctic-0.95-release.tar.bz2 #FEMALE2\n",
        "# !tar -xf cmu_us_slt_arctic-0.95-release.tar.bz2\n",
        "\n",
        "#GTZAN dataset for music genre transfer\n",
        "# !wget --header=\"Host: opihi.cs.uvic.ca\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: http://marsyas.info/downloads/datasets.html\" \"http://opihi.cs.uvic.ca/sound/genres.tar.gz\" -O \"genres.tar.gz\" -c\n",
        "# !tar -xzf genres.tar.gz\n",
        "\n",
        "!ls\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjhttThSBLTj"
      },
      "source": [
        "##Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LEvqwT96l_Yq"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "\n",
        "from __future__ import print_function, division\n",
        "from glob import glob\n",
        "import scipy\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Concatenate, Conv2D, Conv2DTranspose, GlobalAveragePooling2D, UpSampling2D, LeakyReLU, ReLU, Add, Multiply, Lambda, Dot, BatchNormalization, Activation, ZeroPadding2D, Cropping2D, Cropping1D\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import TruncatedNormal, he_normal\n",
        "import tensorflow.keras.backend as K\n",
        "import datetime\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "import imageio\n",
        "import librosa\n",
        "import librosa.display\n",
        "from librosa.feature import melspectrogram\n",
        "import os\n",
        "import time\n",
        "import IPython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmTiDkeW_lJq"
      },
      "source": [
        "\n",
        "# Defining Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KbaM4WKrvO7r"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "\n",
        "hop= 192              #hop size (window size = 6*hop)\n",
        "sr=16000              #sampling rate\n",
        "min_level_db=-100     #reference values to normalize data\n",
        "ref_level_db=20\n",
        "\n",
        "shape=24             #length of time axis of split specrograms to feed to generator            \n",
        "vec_len=128           #length of vector generated by siamese vector\n",
        "bs = 16               #batch size\n",
        "delta = 2.            #constant for siamese loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8CmpLex_zWA"
      },
      "source": [
        "# Mel-spectogram generation and waveform reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9pIPj9hnyJ0",
        "outputId": "7c5c70e7-f558-4ab2-a392-e5d606446c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (192) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#There seems to be a problem with Tensorflow STFT, so we'll be using pytorch to handle offline mel-spectrogram generation and waveform reconstruction\n",
        "#For waveform reconstruction, a gradient-based method is used:\n",
        "\n",
        "''' Decorsière, Rémi, Peter L. Søndergaard, Ewen N. MacDonald, and Torsten Dau. \n",
        "\"Inversion of auditory spectrograms, traditional spectrograms, and other envelope representations.\" \n",
        "IEEE/ACM Transactions on Audio, Speech, and Language Processing 23, no. 1 (2014): 46-56.'''\n",
        "\n",
        "#ORIGINAL CODE FROM https://github.com/yoyololicon/spectrogram-inversion\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "import math\n",
        "import heapq\n",
        "from torchaudio.transforms import MelScale, Spectrogram\n",
        "\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "specobj = Spectrogram(n_fft=6*hop, win_length=6*hop, hop_length=hop, pad=0, power=2, normalized=True)\n",
        "specfunc = specobj.forward\n",
        "melobj = MelScale(n_mels=hop, sample_rate=sr, f_min=0.)\n",
        "melfunc = melobj.forward\n",
        "\n",
        "def melspecfunc(waveform):\n",
        "  specgram = specfunc(waveform)\n",
        "  mel_specgram = melfunc(specgram)\n",
        "  return mel_specgram\n",
        "\n",
        "def spectral_convergence(input, target):\n",
        "    return 20 * ((input - target).norm().log10() - target.norm().log10())\n",
        "\n",
        "def GRAD(spec, transform_fn, samples=None, init_x0=None, maxiter=1000, tol=1e-6, verbose=1, evaiter=10, lr=0.003):\n",
        "\n",
        "    spec = torch.Tensor(spec)\n",
        "    samples = (spec.shape[-1]*hop)-hop\n",
        "\n",
        "    if init_x0 is None:\n",
        "        init_x0 = spec.new_empty((1,samples)).normal_(std=1e-6)\n",
        "    x = nn.Parameter(init_x0)\n",
        "    T = spec\n",
        "\n",
        "    criterion = nn.L1Loss()\n",
        "    optimizer = torch.optim.Adam([x], lr=lr)\n",
        "\n",
        "    bar_dict = {}\n",
        "    metric_func = spectral_convergence\n",
        "    bar_dict['spectral_convergence'] = 0\n",
        "    metric = 'spectral_convergence'\n",
        "\n",
        "    init_loss = None\n",
        "    with tqdm(total=maxiter, disable=not verbose) as pbar:\n",
        "        for i in range(maxiter):\n",
        "            optimizer.zero_grad()\n",
        "            V = transform_fn(x)\n",
        "            loss = criterion(V, T)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr = lr*0.9999\n",
        "            for param_group in optimizer.param_groups:\n",
        "              param_group['lr'] = lr\n",
        "\n",
        "            if i % evaiter == evaiter - 1:\n",
        "                with torch.no_grad():\n",
        "                    V = transform_fn(x)\n",
        "                    bar_dict[metric] = metric_func(V, spec).item()\n",
        "                    l2_loss = criterion(V, spec).item()\n",
        "                    pbar.set_postfix(**bar_dict, loss=l2_loss)\n",
        "                    pbar.update(evaiter)\n",
        "\n",
        "    return x.detach().view(-1).cpu()\n",
        "\n",
        "def normalize(S):\n",
        "  return np.clip((((S - min_level_db) / -min_level_db)*2.)-1., -1, 1)\n",
        "\n",
        "def denormalize(S):\n",
        "  return (((np.clip(S, -1, 1)+1.)/2.) * -min_level_db) + min_level_db\n",
        "\n",
        "def prep(wv,hop=192):\n",
        "  S = np.array(torch.squeeze(melspecfunc(torch.Tensor(wv).view(1,-1))).detach().cpu())\n",
        "  S = librosa.power_to_db(S)-ref_level_db\n",
        "  return normalize(S)\n",
        "\n",
        "def deprep(S):\n",
        "  S = denormalize(S)+ref_level_db\n",
        "  S = librosa.db_to_power(S)\n",
        "  wv = GRAD(np.expand_dims(S,0), melspecfunc, maxiter=2000, evaiter=10, tol=1e-8)\n",
        "  return np.array(np.squeeze(wv))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POzlF3KKBfpz"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YNRYjsCDqDjF"
      },
      "outputs": [],
      "source": [
        "#Helper functions\n",
        "\n",
        "#Generate spectrograms from waveform array\n",
        "def tospec(data):\n",
        "  specs=np.empty(data.shape[0], dtype=object)\n",
        "  for i in range(data.shape[0]):\n",
        "    x = data[i]\n",
        "    S=prep(x)\n",
        "    S = np.array(S, dtype=np.float32)\n",
        "    specs[i]=np.expand_dims(S, -1)\n",
        "  print(specs.shape)\n",
        "  return specs\n",
        "\n",
        "#Generate multiple spectrograms with a determined length from single wav file\n",
        "def tospeclong(path, length=4*16000):\n",
        "  x, sr = librosa.load(path,sr=16000)\n",
        "  x,_ = librosa.effects.trim(x)\n",
        "  loudls = librosa.effects.split(x, top_db=50)\n",
        "  xls = np.array([])\n",
        "  for interv in loudls:\n",
        "    xls = np.concatenate((xls,x[interv[0]:interv[1]]))\n",
        "  x = xls\n",
        "  num = x.shape[0]//length\n",
        "  specs=np.empty(num, dtype=object)\n",
        "  for i in range(num-1):\n",
        "    a = x[i*length:(i+1)*length]\n",
        "    S = prep(a)\n",
        "    S = np.array(S, dtype=np.float32)\n",
        "    try:\n",
        "      sh = S.shape\n",
        "      specs[i]=S\n",
        "    except AttributeError:\n",
        "      print('spectrogram failed')\n",
        "  print(specs.shape)\n",
        "  return specs\n",
        "\n",
        "#Waveform array from path of folder containing wav files\n",
        "def audio_array(path):\n",
        "  ls = glob(f'{path}/*.wav')\n",
        "  adata = []\n",
        "  for i in range(len(ls)):\n",
        "    try:\n",
        "      x, sr = tf.audio.decode_wav(tf.io.read_file(ls[i]), 1)\n",
        "    except:\n",
        "      print(ls[i],\" is broken\")\n",
        "      # os.remove(ls[i])\n",
        "      # print(ls[i],\"is removed\")\n",
        "      continue\n",
        "    x = np.array(x, dtype=np.float32)\n",
        "    adata.append(x)\n",
        "  return np.array(adata)\n",
        "\n",
        "\n",
        "#Concatenate spectrograms in array along the time axis\n",
        "def testass(a):\n",
        "  but=False\n",
        "  con = np.array([])\n",
        "  nim = a.shape[0]\n",
        "  for i in range(nim):\n",
        "    im = a[i]\n",
        "    im = np.squeeze(im)\n",
        "    if not but:\n",
        "      con=im\n",
        "      but=True\n",
        "    else:\n",
        "      con = np.concatenate((con,im), axis=1)\n",
        "  return np.squeeze(con)\n",
        "\n",
        "#Split spectrograms in chunks with equal size\n",
        "def splitcut(data):\n",
        "  ls = []\n",
        "  mini = 0\n",
        "  minifinal = 10*shape                                                              #max spectrogram length\n",
        "  for i in range(data.shape[0]-1):\n",
        "    if data[i].shape[1]<=data[i+1].shape[1]:\n",
        "      mini = data[i].shape[1]\n",
        "    else:\n",
        "      mini = data[i+1].shape[1]\n",
        "    if mini>=3*shape and mini<minifinal:\n",
        "      minifinal = mini\n",
        "  for i in range(data.shape[0]):\n",
        "    x = data[i]\n",
        "    if x.shape[1]>=3*shape:\n",
        "      for n in range(x.shape[1]//minifinal):\n",
        "        ls.append(x[:,n*minifinal:n*minifinal+minifinal,:])\n",
        "      ls.append(x[:,-minifinal:,:])\n",
        "  return np.array(ls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEHQBC3NBoNP"
      },
      "source": [
        "# Preparing dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMM4pBG3Bw_r"
      },
      "source": [
        "##Generating dataset to Mel-Spectogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "tK_UnhfMELHD",
        "outputId": "00db2b75-ca41-4a6d-c51d-70da800cd63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-e145933340a9>:51: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(adata)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8e2cd0a256db>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Lo-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/cmu_us_bdl_arctic/wav\"\u001b[0m\u001b[0;34m)\u001b[0m                               \u001b[0;31m#get waveform array from folder containing wav files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtospec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbwv\u001b[0m\u001b[0;34m)\u001b[0m                                                                 \u001b[0;31m#get spectrogram array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mbdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbspec\u001b[0m\u001b[0;34m)\u001b[0m                                                             \u001b[0;31m#split spectrogams to fixed length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#MALE1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e145933340a9>\u001b[0m in \u001b[0;36mtospec\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-84bbe915f261>\u001b[0m in \u001b[0;36mprep\u001b[0;34m(wv, hop)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m   \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspecfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m   \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mref_level_db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-84bbe915f261>\u001b[0m in \u001b[0;36mmelspecfunc\u001b[0;34m(waveform)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmelspecfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mspecgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mmel_specgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmelfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecgram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmel_specgram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/transforms/_transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, specgram)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# (..., time, freq) dot (freq, n_mels) -> (..., n_mels, time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mmel_specgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmel_specgram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (166x577 and 201x192)"
          ]
        }
      ],
      "source": [
        "#Generating Mel-Spectrogram dataset (Uncomment where needed)\n",
        "#adata: source spectrograms\n",
        "#bdata: target spectrograms\n",
        "\n",
        "#Female1\n",
        "bwv = audio_array(\"/content/cmu_us_bdl_arctic/wav\")                               #get waveform array from folder containing wav files\n",
        "bspec = tospec(bwv)                                                                 #get spectrogram array\n",
        "bdata = splitcut(bspec)                                                             #split spectrogams to fixed length\n",
        "#MALE1\n",
        "awv = audio_array(\"/content/cmu_us_clb_arctic/wav\")\n",
        "aspec = tospec(awv)\n",
        "adata = splitcut(aspec)\n",
        "# #MALE2\n",
        "# awv = audio_array('../content/cmu_us_rms_arctic/wav')\n",
        "# aspec = tospec(awv)\n",
        "# adata = splitcut(aspec)\n",
        "# #FEMALE2\n",
        "# bwv = audio_array('../content/cmu_us_slt_arctic/wav')\n",
        "# bspec = tospec(bwv)\n",
        "# bdata = splitcut(bspec)\n",
        "\n",
        "#JAZZ MUSIC\n",
        "# awv = audio_array('../content/genres/jazz')\n",
        "# aspec = tospec(awv)\n",
        "# adata = splitcut(aspec)\n",
        "#CLASSICAL MUSIC\n",
        "# bwv = audio_array('../content/genres/classical')\n",
        "# bspec = tospec(bwv)\n",
        "# bdata = splitcut(bspec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYwazxX2B3eM"
      },
      "source": [
        "##Creating Tensorflow datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSesIbwr_GyO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "c9277565-6c8f-4641-f8cf-3d8e849b969b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-601b4ee26cb6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdsb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# @tf.function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bdata' is not defined"
          ]
        }
      ],
      "source": [
        "#Creating Tensorflow Datasets\n",
        "\n",
        "@tf.function\n",
        "def proc(x):\n",
        "  return tf.image.random_crop(x, size=[hop, 3*shape, 1])\n",
        "\n",
        "dsb = tf.data.Dataset.from_tensor_slices(bdata).repeat(50).map(proc, num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(10000).batch(bs, drop_remainder=True)\n",
        "dsa = tf.data.Dataset.from_tensor_slices(adata).repeat(50).map(proc, num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(10000).batch(bs, drop_remainder=True)\n",
        "# @tf.function\n",
        "# def proc(x):\n",
        "#     return tf.image.random_crop(x, size=[hop, 3*shape, 3])\n",
        "\n",
        "# dsa = tf.data.Dataset.from_tensor_slices(adata).repeat(50).map(proc, num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(10000).batch(bs, drop_remainder=True)\n",
        "# dsb = tf.data.Dataset.from_tensor_slices(bdata).repeat(50).map(proc, num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(10000).batch(bs, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQzVJIYNFqwq"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAT4O1ENFZcQ"
      },
      "source": [
        "##Adding Spectral Normalization to convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHnP2zr7Ypgi"
      },
      "outputs": [],
      "source": [
        "#Adding Spectral Normalization to convolutional layers\n",
        "\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import sparse_ops\n",
        "from tensorflow.python.ops import gen_math_ops\n",
        "from tensorflow.python.ops import standard_ops\n",
        "from tensorflow.python.eager import context\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "\n",
        "def l2normalize(v, eps=1e-12):\n",
        "    return v / (tf.norm(v) + eps)\n",
        "\n",
        "\n",
        "class ConvSN2D(tf.keras.layers.Conv2D):\n",
        "\n",
        "    def __init__(self, filters, kernel_size, power_iterations=1, **kwargs):\n",
        "        super(ConvSN2D, self).__init__(filters, kernel_size, **kwargs)\n",
        "        self.power_iterations = power_iterations\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ConvSN2D, self).build(input_shape)\n",
        "\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "\n",
        "        self.u = self.add_weight(self.name + '_u',\n",
        "            shape=tuple([1, self.kernel.shape.as_list()[-1]]), \n",
        "            initializer=tf.initializers.RandomNormal(0, 1),\n",
        "            trainable=False\n",
        "        )\n",
        "\n",
        "    def compute_spectral_norm(self, W, new_u, W_shape):\n",
        "        for _ in range(self.power_iterations):\n",
        "\n",
        "            new_v = l2normalize(tf.matmul(new_u, tf.transpose(W)))\n",
        "            new_u = l2normalize(tf.matmul(new_v, W))\n",
        "            \n",
        "        sigma = tf.matmul(tf.matmul(new_v, W), tf.transpose(new_u))\n",
        "        W_bar = W/sigma\n",
        "\n",
        "        with tf.control_dependencies([self.u.assign(new_u)]):\n",
        "          W_bar = tf.reshape(W_bar, W_shape)\n",
        "\n",
        "        return W_bar\n",
        "\n",
        "    def convolution_op(self, inputs, kernel):\n",
        "        if self.padding == \"causal\":\n",
        "            tf_padding = \"VALID\"  # Causal padding handled in `call`.\n",
        "        elif isinstance(self.padding, str):\n",
        "            tf_padding = self.padding.upper()\n",
        "        else:\n",
        "            tf_padding = self.padding\n",
        "\n",
        "        return tf.nn.convolution(\n",
        "            inputs,\n",
        "            kernel,\n",
        "            strides=list(self.strides),\n",
        "            padding=tf_padding,\n",
        "            dilations=list(self.dilation_rate),\n",
        "        )\n",
        "    def call(self, inputs):\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        W_reshaped = tf.reshape(self.kernel, (-1, W_shape[-1]))\n",
        "        new_kernel = self.compute_spectral_norm(W_reshaped, self.u, W_shape)\n",
        "        outputs = self.convolution_op(inputs, new_kernel)\n",
        "\n",
        "        if self.use_bias:\n",
        "            if self.data_format == 'channels_first':\n",
        "                    outputs = tf.nn.bias_add(outputs, self.bias, data_format='NCHW')\n",
        "            else:\n",
        "                outputs = tf.nn.bias_add(outputs, self.bias, data_format='NHWC')\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class ConvSN2DTranspose(tf.keras.layers.Conv2DTranspose):\n",
        "\n",
        "    def __init__(self, filters, kernel_size, power_iterations=1, **kwargs):\n",
        "        super(ConvSN2DTranspose, self).__init__(filters, kernel_size, **kwargs)\n",
        "        self.power_iterations = power_iterations\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ConvSN2DTranspose, self).build(input_shape)\n",
        "\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "\n",
        "        self.u = self.add_weight(self.name + '_u',\n",
        "            shape=tuple([1, self.kernel.shape.as_list()[-1]]), \n",
        "            initializer=tf.initializers.RandomNormal(0, 1),\n",
        "            trainable=False\n",
        "        )\n",
        "\n",
        "    def compute_spectral_norm(self, W, new_u, W_shape):\n",
        "        for _ in range(self.power_iterations):\n",
        "\n",
        "            new_v = l2normalize(tf.matmul(new_u, tf.transpose(W)))\n",
        "            new_u = l2normalize(tf.matmul(new_v, W))\n",
        "            \n",
        "        sigma = tf.matmul(tf.matmul(new_v, W), tf.transpose(new_u))\n",
        "        W_bar = W/sigma\n",
        "\n",
        "        with tf.control_dependencies([self.u.assign(new_u)]):\n",
        "          W_bar = tf.reshape(W_bar, W_shape)\n",
        "\n",
        "        return W_bar\n",
        "\n",
        "    def call(self, inputs):\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        W_reshaped = tf.reshape(self.kernel, (-1, W_shape[-1]))\n",
        "        new_kernel = self.compute_spectral_norm(W_reshaped, self.u, W_shape)\n",
        "\n",
        "        inputs_shape = array_ops.shape(inputs)\n",
        "        batch_size = inputs_shape[0]\n",
        "        if self.data_format == 'channels_first':\n",
        "          h_axis, w_axis = 2, 3\n",
        "        else:\n",
        "          h_axis, w_axis = 1, 2\n",
        "\n",
        "        height, width = inputs_shape[h_axis], inputs_shape[w_axis]\n",
        "        kernel_h, kernel_w = self.kernel_size\n",
        "        stride_h, stride_w = self.strides\n",
        "\n",
        "        if self.output_padding is None:\n",
        "          out_pad_h = out_pad_w = None\n",
        "        else:\n",
        "          out_pad_h, out_pad_w = self.output_padding\n",
        "\n",
        "        out_height = conv_utils.deconv_output_length(height,\n",
        "                                                    kernel_h,\n",
        "                                                    padding=self.padding,\n",
        "                                                    output_padding=out_pad_h,\n",
        "                                                    stride=stride_h,\n",
        "                                                    dilation=self.dilation_rate[0])\n",
        "        out_width = conv_utils.deconv_output_length(width,\n",
        "                                                    kernel_w,\n",
        "                                                    padding=self.padding,\n",
        "                                                    output_padding=out_pad_w,\n",
        "                                                    stride=stride_w,\n",
        "                                                    dilation=self.dilation_rate[1])\n",
        "        if self.data_format == 'channels_first':\n",
        "          output_shape = (batch_size, self.filters, out_height, out_width)\n",
        "        else:\n",
        "          output_shape = (batch_size, out_height, out_width, self.filters)\n",
        "\n",
        "        output_shape_tensor = array_ops.stack(output_shape)\n",
        "        outputs = K.conv2d_transpose(\n",
        "            inputs,\n",
        "            new_kernel,\n",
        "            output_shape_tensor,\n",
        "            strides=self.strides,\n",
        "            padding=self.padding,\n",
        "            data_format=self.data_format,\n",
        "            dilation_rate=self.dilation_rate)\n",
        "\n",
        "        if not context.executing_eagerly():\n",
        "          out_shape = self.compute_output_shape(inputs.shape)\n",
        "          outputs.set_shape(out_shape)\n",
        "\n",
        "        if self.use_bias:\n",
        "          outputs = tf.nn.bias_add(\n",
        "              outputs,\n",
        "              self.bias,\n",
        "              data_format=conv_utils.convert_data_format(self.data_format, ndim=4))\n",
        "\n",
        "        if self.activation is not None:\n",
        "          return self.activation(outputs)\n",
        "        return outputs  \n",
        "    \n",
        "    \n",
        "class DenseSN(Dense):\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        super(DenseSN, self).build(input_shape)\n",
        "\n",
        "        self.u = self.add_weight(self.name + '_u',\n",
        "            shape=tuple([1, self.kernel.shape.as_list()[-1]]), \n",
        "            initializer=tf.initializers.RandomNormal(0, 1),\n",
        "            trainable=False)\n",
        "        \n",
        "    def compute_spectral_norm(self, W, new_u, W_shape):\n",
        "        new_v = l2normalize(tf.matmul(new_u, tf.transpose(W)))\n",
        "        new_u = l2normalize(tf.matmul(new_v, W))\n",
        "        sigma = tf.matmul(tf.matmul(new_v, W), tf.transpose(new_u))\n",
        "        W_bar = W/sigma\n",
        "        with tf.control_dependencies([self.u.assign(new_u)]):\n",
        "          W_bar = tf.reshape(W_bar, W_shape)\n",
        "        return W_bar\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        W_reshaped = tf.reshape(self.kernel, (-1, W_shape[-1]))\n",
        "        new_kernel = self.compute_spectral_norm(W_reshaped, self.u, W_shape)\n",
        "        rank = len(inputs.shape)\n",
        "        if rank > 2:\n",
        "          outputs = standard_ops.tensordot(inputs, new_kernel, [[rank - 1], [0]])\n",
        "          if not context.executing_eagerly():\n",
        "            shape = inputs.shape.as_list()\n",
        "            output_shape = shape[:-1] + [self.units]\n",
        "            outputs.set_shape(output_shape)\n",
        "        else:\n",
        "          inputs = math_ops.cast(inputs, self._compute_dtype)\n",
        "          if K.is_sparse(inputs):\n",
        "            outputs = sparse_ops.sparse_tensor_dense_matmul(inputs, new_kernel)\n",
        "          else:\n",
        "            outputs = gen_math_ops.mat_mul(inputs, new_kernel)\n",
        "        if self.use_bias:\n",
        "          outputs = tf.nn.bias_add(outputs, self.bias)\n",
        "        if self.activation is not None:\n",
        "          return self.activation(outputs)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saCtOi_RFvXU"
      },
      "source": [
        "##Networks Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX41awYeHE1N"
      },
      "outputs": [],
      "source": [
        "#Networks Architecture\n",
        "\n",
        "init = tf.keras.initializers.he_uniform()\n",
        "\n",
        "def conv2d(layer_input, filters, kernel_size=4, strides=2, padding='same', leaky=True, bnorm=True, sn=True):\n",
        "  if leaky:\n",
        "    Activ = LeakyReLU(alpha=0.2)\n",
        "  else:\n",
        "    Activ = ReLU()\n",
        "  if sn:\n",
        "    d = ConvSN2D(filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer=init, use_bias=False)(layer_input)\n",
        "  else:\n",
        "    d = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer=init, use_bias=False)(layer_input)\n",
        "  if bnorm:\n",
        "    d = BatchNormalization()(d)\n",
        "  d = Activ(d)\n",
        "  return d\n",
        "\n",
        "def deconv2d(layer_input, layer_res, filters, kernel_size=4, conc=True, scalev=False, bnorm=True, up=True, padding='same', strides=2):\n",
        "  if up:\n",
        "    u = UpSampling2D((1,2))(layer_input)\n",
        "    u = ConvSN2D(filters, kernel_size, strides=(1,1), kernel_initializer=init, use_bias=False, padding=padding)(u)\n",
        "  else:\n",
        "    u = ConvSN2DTranspose(filters, kernel_size, strides=strides, kernel_initializer=init, use_bias=False, padding=padding)(layer_input)\n",
        "  if bnorm:\n",
        "    u = BatchNormalization()(u)\n",
        "  u = LeakyReLU(alpha=0.2)(u)\n",
        "  if conc:\n",
        "    u = Concatenate()([u,layer_res])\n",
        "  return u\n",
        "\n",
        "#Extract function: splitting spectrograms\n",
        "def extract_image(im):\n",
        "  im1 = Cropping2D(((0,0), (0, 2*(im.shape[2]//3))))(im)\n",
        "  im2 = Cropping2D(((0,0), (im.shape[2]//3,im.shape[2]//3)))(im)\n",
        "  im3 = Cropping2D(((0,0), (2*(im.shape[2]//3), 0)))(im)\n",
        "  return im1,im2,im3\n",
        "\n",
        "#Assemble function: concatenating spectrograms\n",
        "def assemble_image(lsim):\n",
        "  im1,im2,im3 = lsim\n",
        "  imh = Concatenate(2)([im1,im2,im3])\n",
        "  return imh\n",
        "\n",
        "#U-NET style architecture\n",
        "def build_generator(input_shape):\n",
        "  h,w,c = input_shape\n",
        "  inp = Input(shape=input_shape)\n",
        "  #downscaling\n",
        "  g0 = tf.keras.layers.ZeroPadding2D((0,1))(inp)\n",
        "  g1 = conv2d(g0, 256, kernel_size=(h,3), strides=1, padding='valid')\n",
        "  g2 = conv2d(g1, 256, kernel_size=(1,9), strides=(1,2))\n",
        "  g3 = conv2d(g2, 256, kernel_size=(1,7), strides=(1,2))\n",
        "  #upscaling\n",
        "  g4 = deconv2d(g3,g2, 256, kernel_size=(1,7), strides=(1,2))\n",
        "  g5 = deconv2d(g4,g1, 256, kernel_size=(1,9), strides=(1,2), bnorm=False)\n",
        "  g6 = ConvSN2DTranspose(1, kernel_size=(h,1), strides=(1,1), kernel_initializer=init, padding='valid', activation='tanh')(g5)\n",
        "  return Model(inp,g6, name='G')\n",
        "\n",
        "#Siamese Network\n",
        "def build_siamese(input_shape):\n",
        "  h,w,c = input_shape\n",
        "  inp = Input(shape=input_shape)\n",
        "  g1 = conv2d(inp, 256, kernel_size=(h,3), strides=1, padding='valid', sn=False)\n",
        "  g2 = conv2d(g1, 256, kernel_size=(1,9), strides=(1,2), sn=False)\n",
        "  g3 = conv2d(g2, 256, kernel_size=(1,7), strides=(1,2), sn=False)\n",
        "  g4 = Flatten()(g3)\n",
        "  g5 = Dense(vec_len)(g4)\n",
        "  return Model(inp, g5, name='S')\n",
        "\n",
        "#Discriminator (Critic) Network\n",
        "def build_critic(input_shape):\n",
        "  h,w,c = input_shape\n",
        "  inp = Input(shape=input_shape)\n",
        "  g1 = conv2d(inp, 512, kernel_size=(h,3), strides=1, padding='valid', bnorm=False)\n",
        "  g2 = conv2d(g1, 512, kernel_size=(1,9), strides=(1,2), bnorm=False)\n",
        "  g3 = conv2d(g2, 512, kernel_size=(1,7), strides=(1,2), bnorm=False)\n",
        "  g4 = Flatten()(g3)\n",
        "  g4 = DenseSN(1, kernel_initializer=init)(g4)\n",
        "  return Model(inp, g4, name='C')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tvD7aQtFz84"
      },
      "source": [
        "##Loading Past models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fXJmItOzrhC"
      },
      "outputs": [],
      "source": [
        "#Load past models from path to resume training or test\n",
        "def load(path):\n",
        "  gen = build_generator((hop,shape,1))\n",
        "  siam = build_siamese((hop,shape,1))\n",
        "  critic = build_critic((hop,3*shape,1))\n",
        "  gen.load_weights(path+'/gen.h5') #\n",
        "  critic.load_weights(path+'/critic.h5')\n",
        "  siam.load_weights(path+'/siam.h5')\n",
        "  return gen,critic,siam\n",
        "\n",
        "#Build models\n",
        "def build():\n",
        "  gen = build_generator((hop,shape,1))\n",
        "  siam = build_siamese((hop,shape,1))\n",
        "  critic = build_critic((hop,3*shape,1))                                          #the discriminator accepts as input spectrograms of triple the width of those generated by the generator\n",
        "  return gen,critic,siam\n",
        "\n",
        "#Generate a random batch to display current training results\n",
        "def testgena():\n",
        "  sw = True\n",
        "  while sw:\n",
        "    a = np.random.choice(aspec)\n",
        "    if a.shape[1]//shape!=1:\n",
        "      sw=False\n",
        "  dsa = []\n",
        "  if a.shape[1]//shape>6:\n",
        "    num=6\n",
        "  else:\n",
        "    num=a.shape[1]//shape\n",
        "  try:\n",
        "    rn = np.random.randint(a.shape[1]-(num*shape))\n",
        "  except:\n",
        "    pass\n",
        "  for i in range(num):\n",
        "    im = a[:,rn+(i*shape):rn+(i*shape)+shape]\n",
        "    im = np.reshape(im, (im.shape[0],im.shape[1],1))\n",
        "    dsa.append(im)\n",
        "  return np.array(dsa, dtype=np.float32)\n",
        "\n",
        "#Show results mid-training\n",
        "def save_test_image_full(path):\n",
        "  a = testgena()\n",
        "  print(a.shape)\n",
        "  ab = gen(a, training=False)\n",
        "  ab = testass(ab)\n",
        "  a = testass(a)\n",
        "  abwv = deprep(ab)\n",
        "  awv = deprep(a)\n",
        "  sf.write(path+'/new_file.wav', abwv, sr)\n",
        "  IPython.display.display(IPython.display.Audio(np.squeeze(abwv), rate=sr))\n",
        "  IPython.display.display(IPython.display.Audio(np.squeeze(awv), rate=sr))\n",
        "  fig, axs = plt.subplots(ncols=2)\n",
        "  axs[0].imshow(np.flip(a, -2), cmap=None)\n",
        "  axs[0].axis('off')\n",
        "  axs[0].set_title('Source')\n",
        "  axs[1].imshow(np.flip(ab, -2), cmap=None)\n",
        "  axs[1].axis('off')\n",
        "  axs[1].set_title('Generated')\n",
        "  plt.show()\n",
        "\n",
        "#Save in training loop\n",
        "def save_end(epoch,gloss,closs,mloss,n_save=3,save_path='/content/models'):                 #use custom save_path (i.e. Drive '../content/drive/My Drive/')\n",
        "  if epoch % n_save == 0:\n",
        "    print('Saving...')\n",
        "    path = f'{save_path}/MELGANVC-{str(gloss)[:9]}-{str(closs)[:9]}-{str(mloss)[:9]}'\n",
        "    print(path)\n",
        "    os.mkdir(path)\n",
        "    gen.save_weights(path+'/gen.h5')\n",
        "    critic.save_weights(path+'/critic.h5')\n",
        "    siam.save_weights(path+'/siam.h5')\n",
        "    # save_test_image_full(path)                                                        #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOwKGOQQwbFI"
      },
      "outputs": [],
      "source": [
        "test1=testgena()\n",
        "test1.shape\n",
        "test2 = np.random.choice(aspec)\n",
        "test3=np.random.choice(aspec)\n",
        "try:  \n",
        "  rn = np.random.randint(test3.shape[1]-(6*shape))\n",
        "except:\n",
        "  pass\n",
        "im = test1[:,rn+(5*shape):rn+(5*shape)+shape]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUvSFQxU0FVB",
        "outputId": "13ef8115-6d90-44d8-be87-53ca6e6ce91b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 6, 24, 24, 1)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lisa=[]\n",
        "im.shape\n",
        "lisa.append(im)\n",
        "lisad=np.array(lisa)\n",
        "lisad.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCUjMJcjF-Hj"
      },
      "source": [
        "##Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn2s65AxjDJ8"
      },
      "outputs": [],
      "source": [
        "#Losses\n",
        "\n",
        "def mae(x,y):\n",
        "  return tf.reduce_mean(tf.abs(x-y))\n",
        "\n",
        "def mse(x,y):\n",
        "  return tf.reduce_mean((x-y)**2)\n",
        "\n",
        "def loss_travel(sa,sab,sa1,sab1):\n",
        "  l1 = tf.reduce_mean(((sa-sa1) - (sab-sab1))**2)\n",
        "  l2 = tf.reduce_mean(tf.reduce_sum(-(tf.nn.l2_normalize(sa-sa1, axis=[-1]) * tf.nn.l2_normalize(sab-sab1, axis=[-1])), axis=-1))\n",
        "  return l1+l2\n",
        "\n",
        "def loss_siamese(sa,sa1):\n",
        "  logits = tf.sqrt(tf.reduce_sum((sa-sa1)**2, axis=-1, keepdims=True))\n",
        "  return tf.reduce_mean(tf.square(tf.maximum((delta - logits), 0)))\n",
        "\n",
        "def d_loss_f(fake):\n",
        "  return tf.reduce_mean(tf.maximum(1 + fake, 0))\n",
        "\n",
        "def d_loss_r(real):\n",
        "  return tf.reduce_mean(tf.maximum(1 - real, 0))\n",
        "\n",
        "def g_loss_f(fake):\n",
        "  return tf.reduce_mean(- fake)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj2RiLqXGEId"
      },
      "source": [
        "##Get models and optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgjxHjyIhPwl"
      },
      "outputs": [],
      "source": [
        "#Get models and optimizers\n",
        "def get_networks(shape, load_model=False, path=None):\n",
        "  if not load_model:\n",
        "    gen,critic,siam = build()\n",
        "  else:\n",
        "    gen,critic,siam = load(path)\n",
        "  print('Built networks')\n",
        "\n",
        "\n",
        "  opt_gen = Adam(0.0001, 0.5)\n",
        "  opt_disc = Adam(0.0001, 0.5)\n",
        "\n",
        "  return gen,critic,siam, [opt_gen,opt_disc]\n",
        "\n",
        "#Set learning rate\n",
        "def update_lr(lr):\n",
        "  opt_gen.learning_rate = lr\n",
        "  opt_disc.learning_rate = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOel1pPPGKxU"
      },
      "source": [
        "##Training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGWjgHqDWR78"
      },
      "outputs": [],
      "source": [
        "#Training Functions\n",
        "\n",
        "#Train Generator, Siamese and Critic\n",
        "@tf.function\n",
        "def train_all(a,b):\n",
        "  #splitting spectrogram in 3 parts\n",
        "  aa,aa2,aa3 = extract_image(a) \n",
        "  bb,bb2,bb3 = extract_image(b)\n",
        "\n",
        "  with tf.GradientTape() as tape_gen, tf.GradientTape() as tape_disc:\n",
        "\n",
        "    #translating A to B\n",
        "    fab = gen(aa, training=True)\n",
        "    fab2 = gen(aa2, training=True)\n",
        "    fab3 = gen(aa3, training=True)\n",
        "    #identity mapping B to B                                                        COMMENT THESE 3 LINES IF THE IDENTITY LOSS TERM IS NOT NEEDED\n",
        "    fid = gen(bb, training=True) \n",
        "    fid2 = gen(bb2, training=True)\n",
        "    fid3 = gen(bb3, training=True)\n",
        "    #concatenate/assemble converted spectrograms\n",
        "    fabtot = assemble_image([fab,fab2,fab3])\n",
        "\n",
        "    #feed concatenated spectrograms to critic\n",
        "    cab = critic(fabtot, training=True)\n",
        "    cb = critic(b, training=True)\n",
        "    #feed 2 pairs (A,G(A)) extracted spectrograms to Siamese\n",
        "    sab = siam(fab, training=True)\n",
        "    sab2 = siam(fab3, training=True)\n",
        "    sa = siam(aa, training=True)\n",
        "    sa2 = siam(aa3, training=True)\n",
        "\n",
        "    #identity mapping loss\n",
        "    loss_id = (mae(bb,fid)+mae(bb2,fid2)+mae(bb3,fid3))/3.                         #loss_id = 0. IF THE IDENTITY LOSS TERM IS NOT NEEDED\n",
        "    #travel loss\n",
        "    loss_m = loss_travel(sa,sab,sa2,sab2)+loss_siamese(sa,sa2)\n",
        "    #generator and critic losses\n",
        "    loss_g = g_loss_f(cab)\n",
        "    loss_dr = d_loss_r(cb)\n",
        "    loss_df = d_loss_f(cab)\n",
        "    loss_d = (loss_dr+loss_df)/2.\n",
        "    #generator+siamese total loss\n",
        "    lossgtot = loss_g+10.*loss_m+0.5*loss_id                                       #CHANGE LOSS WEIGHTS HERE  (COMMENT OUT +w*loss_id IF THE IDENTITY LOSS TERM IS NOT NEEDED)\n",
        "  \n",
        "  #computing and applying gradients\n",
        "  grad_gen = tape_gen.gradient(lossgtot, gen.trainable_variables+siam.trainable_variables)\n",
        "  opt_gen.apply_gradients(zip(grad_gen, gen.trainable_variables+siam.trainable_variables))\n",
        "\n",
        "  grad_disc = tape_disc.gradient(loss_d, critic.trainable_variables)\n",
        "  opt_disc.apply_gradients(zip(grad_disc, critic.trainable_variables))\n",
        "  \n",
        "  return loss_dr,loss_df,loss_g,loss_id\n",
        "\n",
        "#Train Critic only\n",
        "@tf.function\n",
        "def train_d(a,b):\n",
        "  aa,aa2,aa3 = extract_image(a)\n",
        "  with tf.GradientTape() as tape_disc:\n",
        "\n",
        "    fab = gen(aa, training=True)\n",
        "    fab2 = gen(aa2, training=True)\n",
        "    fab3 = gen(aa3, training=True)\n",
        "    fabtot = assemble_image([fab,fab2,fab3])\n",
        "\n",
        "    cab = critic(fabtot, training=True)\n",
        "    cb = critic(b, training=True)\n",
        "\n",
        "    loss_dr = d_loss_r(cb)\n",
        "    loss_df = d_loss_f(cab)\n",
        "\n",
        "    loss_d = (loss_dr+loss_df)/2.\n",
        "  \n",
        "  grad_disc = tape_disc.gradient(loss_d, critic.trainable_variables)\n",
        "  opt_disc.apply_gradients(zip(grad_disc, critic.trainable_variables))\n",
        "\n",
        "  return loss_dr,loss_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh_UK4wmGPeT"
      },
      "source": [
        "##Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVwL-Ry-nNru"
      },
      "outputs": [],
      "source": [
        "#Training Loop\n",
        "\n",
        "def train(epochs, batch_size=16, lr=0.0001, n_save=6, gupt=5):\n",
        "  \n",
        "  update_lr(lr)\n",
        "  df_list = []\n",
        "  dr_list = []\n",
        "  g_list = []\n",
        "  id_list = []\n",
        "  c = 0\n",
        "  g = 0\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "        bef = time.time()\n",
        "        \n",
        "        for batchi,(a,b) in enumerate(zip(dsa,dsb)):\n",
        "          \n",
        "            if batchi%gupt==0:\n",
        "              dloss_t,dloss_f,gloss,idloss = train_all(a,b)\n",
        "            else:\n",
        "              dloss_t,dloss_f = train_d(a,b)\n",
        "\n",
        "            df_list.append(dloss_f)\n",
        "            dr_list.append(dloss_t)\n",
        "            g_list.append(gloss)\n",
        "            id_list.append(idloss)\n",
        "            c += 1\n",
        "            g += 1\n",
        "\n",
        "            if batchi%600==0:\n",
        "                print(f'[Epoch {epoch}/{epochs}] [Batch {batchi}] [D loss f: {np.mean(df_list[-g:], axis=0)} ', end='')\n",
        "                print(f'r: {np.mean(dr_list[-g:], axis=0)}] ', end='')\n",
        "                print(f'[G loss: {np.mean(g_list[-g:], axis=0)}] ', end='')\n",
        "                print(f'[ID loss: {np.mean(id_list[-g:])}] ', end='')\n",
        "                print(f'[LR: {lr}]')\n",
        "                g = 0\n",
        "            nbatch=batchi\n",
        "\n",
        "        print(f'Time/Batch {(time.time()-bef)/nbatch}')\n",
        "        save_end(epoch,np.mean(g_list[-n_save*c:], axis=0),np.mean(df_list[-n_save*c:], axis=0),np.mean(id_list[-n_save*c:], axis=0),n_save=n_save)\n",
        "        print(f'Mean D loss: {np.mean(df_list[-c:], axis=0)} Mean G loss: {np.mean(g_list[-c:], axis=0)} Mean ID loss: {np.mean(id_list[-c:], axis=0)}')\n",
        "        c = 0\n",
        "                      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnzdBcZvGZ7w"
      },
      "source": [
        "##Build models and initialize optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JruweKNrl_ZD",
        "outputId": "d528fb34-31a9-4bd7-b2a7-8c208fc8212a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built networks\n"
          ]
        }
      ],
      "source": [
        "#Build models and initialize optimizers\n",
        "\n",
        "#If load_model=True, specify the path where the models are saved\n",
        "\n",
        "gen,critic,siam, [opt_gen,opt_disc] = get_networks(shape, load_model=False, path=\"/content/models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFM8BNiHGdxI"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BknKCA-8yqap",
        "outputId": "0993334d-b1f4-42aa-a6b0-b7309cdeebf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 0/2] [Batch 0] [D loss f: 1.0999037027359009 r: 0.9540621042251587] [G loss: -0.09990373253822327] [ID loss: 0.46087396144866943] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 600] [D loss f: 0.3072664439678192 r: 0.30092179775238037] [G loss: 1.4800395965576172] [ID loss: 0.2396407276391983] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 1200] [D loss f: 0.48723897337913513 r: 0.5081101655960083] [G loss: 0.836426317691803] [ID loss: 0.1480833739042282] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 1800] [D loss f: 0.4582815170288086 r: 0.4761534035205841] [G loss: 0.971764326095581] [ID loss: 0.13502272963523865] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 2400] [D loss f: 0.45969024300575256 r: 0.44302064180374146] [G loss: 0.9593701362609863] [ID loss: 0.13079331815242767] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 3000] [D loss f: 0.455925852060318 r: 0.43181630969047546] [G loss: 0.8157957196235657] [ID loss: 0.134728342294693] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 3600] [D loss f: 0.4632725119590759 r: 0.39871639013290405] [G loss: 0.8949882984161377] [ID loss: 0.1455143690109253] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 4200] [D loss f: 0.5143956542015076 r: 0.40276119112968445] [G loss: 0.6977006196975708] [ID loss: 0.15778301656246185] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 4800] [D loss f: 0.5401294827461243 r: 0.3876621425151825] [G loss: 0.7382731437683105] [ID loss: 0.1680011749267578] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 5400] [D loss f: 0.5349255204200745 r: 0.3821772336959839] [G loss: 0.6732998490333557] [ID loss: 0.18221110105514526] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 6000] [D loss f: 0.5272219777107239 r: 0.3670138418674469] [G loss: 0.6320547461509705] [ID loss: 0.18415026366710663] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 6600] [D loss f: 0.5507969260215759 r: 0.3663873076438904] [G loss: 0.6906062960624695] [ID loss: 0.18833598494529724] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 7200] [D loss f: 0.5566969513893127 r: 0.3559478223323822] [G loss: 0.6306057572364807] [ID loss: 0.19310253858566284] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 7800] [D loss f: 0.506116509437561 r: 0.3483980596065521] [G loss: 0.667572557926178] [ID loss: 0.1907406747341156] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 8400] [D loss f: 0.49138325452804565 r: 0.3330407440662384] [G loss: 0.6954007744789124] [ID loss: 0.19077473878860474] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 9000] [D loss f: 0.5075652003288269 r: 0.3361113965511322] [G loss: 0.7112370729446411] [ID loss: 0.19116033613681793] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 9600] [D loss f: 0.49757862091064453 r: 0.3493943512439728] [G loss: 0.6870145797729492] [ID loss: 0.18424241244792938] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 10200] [D loss f: 0.4979172348976135 r: 0.3528730869293213] [G loss: 0.6838043332099915] [ID loss: 0.17783664166927338] [LR: 0.0002]\n",
            "[Epoch 0/2] [Batch 10800] [D loss f: 0.46734923124313354 r: 0.3712787926197052] [G loss: 0.7121433615684509] [ID loss: 0.1709832400083542] [LR: 0.0002]\n",
            "Time/Batch 0.048706019942759825\n",
            "Saving...\n",
            "/content/models/MELGANVC-0.7847879-0.4892737-0.1728009\n",
            "Mean D loss: 0.4892737567424774 Mean G loss: 0.7847878932952881 Mean ID loss: 0.17280098795890808\n",
            "[Epoch 1/2] [Batch 0] [D loss f: 0.45138680934906006 r: 0.35966187715530396] [G loss: 0.6807048916816711] [ID loss: 0.16622114181518555] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 600] [D loss f: 0.454166054725647 r: 0.3750261068344116] [G loss: 0.7922438383102417] [ID loss: 0.16071517765522003] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 1200] [D loss f: 0.4608178734779358 r: 0.39765307307243347] [G loss: 0.6138016581535339] [ID loss: 0.1524883210659027] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 1800] [D loss f: 0.4507414698600769 r: 0.4137782156467438] [G loss: 0.6785939335823059] [ID loss: 0.1422756463289261] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 2400] [D loss f: 0.46324899792671204 r: 0.4290171265602112] [G loss: 0.8028094172477722] [ID loss: 0.1388055980205536] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 3000] [D loss f: 0.4632086157798767 r: 0.4424680471420288] [G loss: 0.6649990081787109] [ID loss: 0.13345395028591156] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 3600] [D loss f: 0.45656001567840576 r: 0.46302852034568787] [G loss: 0.748045027256012] [ID loss: 0.12939511239528656] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 4200] [D loss f: 0.46828776597976685 r: 0.4849865734577179] [G loss: 0.7211192846298218] [ID loss: 0.12938185036182404] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 4800] [D loss f: 0.46695780754089355 r: 0.4903965890407562] [G loss: 0.7594987750053406] [ID loss: 0.1284368336200714] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 5400] [D loss f: 0.466278076171875 r: 0.5217791795730591] [G loss: 0.6022676825523376] [ID loss: 0.13091199100017548] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 6000] [D loss f: 0.47003892064094543 r: 0.5429678559303284] [G loss: 0.7378058433532715] [ID loss: 0.1313008964061737] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 6600] [D loss f: 0.47307801246643066 r: 0.5458603501319885] [G loss: 0.732162356376648] [ID loss: 0.13274775445461273] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 7200] [D loss f: 0.4737866222858429 r: 0.5532678961753845] [G loss: 0.6552373170852661] [ID loss: 0.13549278676509857] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 7800] [D loss f: 0.4637017846107483 r: 0.5555811524391174] [G loss: 0.7040653228759766] [ID loss: 0.13631750643253326] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 8400] [D loss f: 0.4724815785884857 r: 0.5696406960487366] [G loss: 0.635303795337677] [ID loss: 0.137465700507164] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 9000] [D loss f: 0.47263795137405396 r: 0.5774221420288086] [G loss: 0.7339492440223694] [ID loss: 0.1384078711271286] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 9600] [D loss f: 0.4819592833518982 r: 0.5753587484359741] [G loss: 0.7142001390457153] [ID loss: 0.13769671320915222] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 10200] [D loss f: 0.46919330954551697 r: 0.593882143497467] [G loss: 0.744770884513855] [ID loss: 0.13959035277366638] [LR: 0.0002]\n",
            "[Epoch 1/2] [Batch 10800] [D loss f: 0.4620683193206787 r: 0.5946646332740784] [G loss: 0.6732244491577148] [ID loss: 0.1395784467458725] [LR: 0.0002]\n",
            "Time/Batch 0.04698155375444617\n",
            "Saving...\n",
            "/content/models/MELGANVC-0.7035468-0.4661224-0.1375632\n",
            "Mean D loss: 0.46612244844436646 Mean G loss: 0.7035468220710754 Mean ID loss: 0.13756324350833893\n"
          ]
        }
      ],
      "source": [
        "#Training\n",
        "\n",
        "#n_save = how many epochs between each saving and displaying of results\n",
        "#gupt = how many discriminator updates for generator+siamese update\n",
        "\n",
        "train(2, batch_size=bs, lr=0.0002, n_save=1, gupt=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evb9-dO2Guje"
      },
      "source": [
        "# Converting data with the generator and save the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBsxDnU2HDZz"
      },
      "source": [
        "##Converting functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-f6nSiF95H-"
      },
      "outputs": [],
      "source": [
        "#After Training, use these functions to convert data with the generator and save the results\n",
        "\n",
        "#Assembling generated Spectrogram chunks into final Spectrogram\n",
        "def specass(a,spec):\n",
        "  but=False\n",
        "  con = np.array([])\n",
        "  nim = a.shape[0]\n",
        "  for i in range(nim-1):\n",
        "    im = a[i]\n",
        "    im = np.squeeze(im)\n",
        "    if not but:\n",
        "      con=im\n",
        "      but=True\n",
        "    else:\n",
        "      con = np.concatenate((con,im), axis=1)\n",
        "  diff = spec.shape[1]-(nim*shape)\n",
        "  a = np.squeeze(a)\n",
        "  con = np.concatenate((con,a[-1,:,-diff:]), axis=1)\n",
        "  return np.squeeze(con)\n",
        "\n",
        "#Splitting input spectrogram into different chunks to feed to the generator\n",
        "def chopspec(spec):\n",
        "  dsa=[]\n",
        "  for i in range(spec.shape[1]//shape):\n",
        "    im = spec[:,i*shape:i*shape+shape]\n",
        "    im = np.reshape(im, (im.shape[0],im.shape[1],1))\n",
        "    dsa.append(im)\n",
        "  imlast = spec[:,-shape:]\n",
        "  imlast = np.reshape(imlast, (imlast.shape[0],imlast.shape[1],1))\n",
        "  dsa.append(imlast)\n",
        "  return np.array(dsa, dtype=np.float32)\n",
        "\n",
        "#Converting from source Spectrogram to target Spectrogram\n",
        "def towave(spec, name, path='../content/', show=False):\n",
        "  specarr = chopspec(spec)\n",
        "  print(specarr.shape)\n",
        "  a = specarr\n",
        "  print('Generating...')\n",
        "  ab = gen(a, training=False)\n",
        "  print('Assembling and Converting...')\n",
        "  a = specass(a,spec)\n",
        "  ab = specass(ab,spec)\n",
        "  awv = deprep(a)\n",
        "  abwv = deprep(ab)\n",
        "  print('Saving...')\n",
        "  pathfin = f'{path}/{name}'\n",
        "  os.mkdir(pathfin)\n",
        "  sf.write(pathfin+'/AB.wav', abwv, sr)\n",
        "  sf.write(pathfin+'/A.wav', awv, sr)\n",
        "  print('Saved WAV!')\n",
        "  IPython.display.display(IPython.display.Audio(np.squeeze(abwv), rate=sr))\n",
        "  IPython.display.display(IPython.display.Audio(np.squeeze(awv), rate=sr))\n",
        "  if show:\n",
        "    fig, axs = plt.subplots(ncols=2)\n",
        "    axs[0].imshow(np.flip(a, -2), cmap=None)\n",
        "    axs[0].axis('off')\n",
        "    axs[0].set_title('Source')\n",
        "    axs[1].imshow(np.flip(ab, -2), cmap=None)\n",
        "    axs[1].axis('off')\n",
        "    axs[1].set_title('Generated')\n",
        "    plt.show()\n",
        "  return abwv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k3xe7RuHLz7"
      },
      "source": [
        "##Wav to wav conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "6FZE91V1BIJX",
        "outputId": "0e1d756e-a68e-412f-f641-2807212eac19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(62160,)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 5000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14, 577, 24, 1)\n",
            "Generating...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-3174d3f9e860>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mabwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtowave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'opt111'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content'\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m#Convert and save wav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-104-2565358d25b9>\u001b[0m in \u001b[0;36mtowave\u001b[0;34m(spec, name, path, show)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecarr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generating...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Assembling and Converting...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    299\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"G\" is incompatible with the layer: expected shape=(None, 192, 24, 1), found shape=(14, 577, 24, 1)"
          ]
        }
      ],
      "source": [
        "#Wav to wav conversion\n",
        "from librosa import load\n",
        "wv, sr = librosa.load(\"/content/arctic_a0002.wav\", sr=16000)  #Load waveform\n",
        "print(wv.shape)\n",
        "speca = prep(wv)                                                    #Waveform to Spectrogram\n",
        "\n",
        "plt.figure(figsize=(50,1))                                          #Show Spectrogram\n",
        "plt.imshow(np.flip(speca, axis=0), cmap=None)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "abwv = towave(speca, name='opt111', path='/content')           #Convert and save wav"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      }
    ],
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "instance_type": "ml.p3.2xlarge",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}